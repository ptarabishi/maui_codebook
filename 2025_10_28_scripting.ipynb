{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efff2b78",
   "metadata": {},
   "source": [
    "# to do: \n",
    " \n",
    "from preprocess notebook\n",
    "- [x] write code for looping through unprocessed files\n",
    "- [x] motion correction script\n",
    "    - fixed nii\n",
    "- [x] clustering script\n",
    "    - labels.h5 - cluster labels\n",
    "    - supervoxel.h5 - ca_signal, brain dimensions\n",
    "- [x] fictrac processing script\n",
    "    - behavior.h5 - fictrac data, camera_fr, scope_fr\n",
    "- clean up ttl calculations? nah\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "64ba21b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T23:50:38.644837Z",
     "start_time": "2025-11-05T23:50:38.642596Z"
    }
   },
   "source": [
    "import glob\n",
    "import h5py\n",
    "import pandas as pd\n",
    "\n",
    "from src import io, moco, roi, ttl, zdF\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "# import nibabel as nib\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "6f568a50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T16:15:20.236403Z",
     "start_time": "2025-10-31T23:33:29.051176Z"
    }
   },
   "source": [
    "# set main data path\n",
    "base_data_path = \"/Volumes/AhmedLab/princess/data\"\n",
    "\n",
    "# loop over all directories within princess/data\n",
    "processed_exps = []\n",
    "unprocessed_exps = []\n",
    "for folder_name in os.listdir(os.path.join(base_data_path,'raw')):\n",
    "\n",
    "    raw_path = os.path.join(base_data_path, 'raw', folder_name)\n",
    "    processed_path = os.path.join(base_data_path, 'processed', folder_name)\n",
    "\n",
    "    # do not run on .DS_Store folder\n",
    "    if folder_name != \".DS_Store\":\n",
    "        # for folders that have a processed + raw folder\n",
    "        # add to processed experiments list\n",
    "        if os.path.isdir(raw_path) and os.path.isdir(processed_path):\n",
    "            processed_exps.append(folder_name)\n",
    "        else:\n",
    "        # on directories that do not have a processed directory\n",
    "            unprocessed_exps.append(folder_name)\n",
    "\n",
    "print(f'processed experiments: {processed_exps}')\n",
    "print(f'unprocessed experiments: {unprocessed_exps}')\n",
    "\n",
    "for exp in unprocessed_exps:\n",
    "    print(f'working on: {exp}')\n",
    "    path = os.path.join(base_data_path, 'raw', exp)\n",
    "\n",
    "    # make processed directory\n",
    "    processed_path = os.path.join(base_data_path, 'processed', exp)\n",
    "    os.mkdir(processed_path)\n",
    "    print('    made processed directory')\n",
    "    # load in functional and structural data\n",
    "    if glob.glob(os.path.join(path, '*channel_2.nii')):\n",
    "        func_channel = glob.glob(os.path.join(path, '*channel_2.nii'))[0]\n",
    "        struc_channel = glob.glob(os.path.join(path, '*channel_1.nii'))[0]\n",
    "    else:\n",
    "        # if there is only data from a single channel\n",
    "        func_channel = glob.glob(os.path.join(path, '*channel_1.nii'))[0]\n",
    "        # use the functional data to generate fixed brain\n",
    "        struc_channel = func_channel\n",
    "\n",
    "    # loads in ENTIRE niis\n",
    "    func_data = io.load_nii(func_channel)\n",
    "    struc_data = io.load_nii(struc_channel)\n",
    "\n",
    "    # loads in partial niis\n",
    "    # func_nii = nib.load(func_channel)\n",
    "    # func_data = func_nii.dataobj[...,:50]\n",
    "    # struc_data = func_data\n",
    "\n",
    "    dimensions = pd.DataFrame(func_data.shape)\n",
    "    print('    running motion correction')\n",
    "    # generate fixed brain\n",
    "    mean_brain, fixed_brain = moco.generate_fixed(struc_data, struc_data.shape[-1])\n",
    "    io.save_nii(f'{processed_path}/fixed.nii', mean_brain)\n",
    "\n",
    "    # run motion correction on functional data and save out motion corrected brain\n",
    "    moco_func_brain = moco.motion_correction(func_data, fixed_brain)\n",
    "    io.save_nii(f'{processed_path}/motion_corrected.nii', moco_func_brain)\n",
    "\n",
    "    print('    clustering pixels')\n",
    "\n",
    "    n_clusters = 1000\n",
    "    cluster_labels = roi.extract_ROIs(moco_func_brain, n_clusters)\n",
    "    print('    calculating df/F signal')\n",
    "    df = zdF.calculate_zscoredF(moco_func_brain, cluster_labels, n_clusters)\n",
    "\n",
    "    # make cluster + zdF h5\n",
    "    hf = h5py.File(f'{processed_path}/{n_clusters}_signals.h5', 'w')\n",
    "    hf.create_dataset('labels', data=cluster_labels)\n",
    "    hf.create_dataset('df/f', data=df)\n",
    "    hf.close()\n",
    "\n",
    "    # load in csv\n",
    "    csv_file = glob.glob(os.path.join(path, '*csv'))[0]\n",
    "\n",
    "    print('    saving acquisition parameters')\n",
    "    ttls = ttl.read_csv(csv_file)\n",
    "    scope_timestamps = ttl.extract_2p_relative_timestamps(ttls)\n",
    "    camera_timestamps = ttl.extract_camera_relative_timestamps(ttls)\n",
    "    scope_framerate = ttl.get_frame_rate(pd.Series(scope_timestamps))\n",
    "    camera_framerate = ttl.get_frame_rate(pd.Series(camera_timestamps))\n",
    "\n",
    "    hf_path = f'{processed_path}/acquisition_parameters.h5'\n",
    "    with h5py.File(hf_path,'w') as hf:\n",
    "        hf.create_dataset('scope_fr', data=scope_framerate)\n",
    "        hf.create_dataset('camera_fr', data=camera_framerate)\n",
    "        hf.create_dataset('brain_dimensions', data = dimensions)\n",
    "    hf.close()\n",
    "    camera_framerate = 170\n",
    "    # load fictrac data\n",
    "    dat_file = glob.glob(os.path.join(path, '*.dat'))[0]\n",
    "    fictrac_data = pd.DataFrame(pd.read_csv(dat_file, header=None))\n",
    "\n",
    "    print('    smoothing and saving fictrac speed')\n",
    "    win_size = int(.5 * camera_framerate)\n",
    "    inst_speed = np.rad2deg(fictrac_data[18])\n",
    "    smoothed_speed = savgol_filter(inst_speed, win_size, 3)\n",
    "\n",
    "    xy_pos = pd.DataFrame({'x': fictrac_data[14], 'y': fictrac_data[15]})\n",
    "    delta_rot = pd.DataFrame({'x': np.rad2deg(fictrac_data[5]), 'y': np.rad2deg(fictrac_data[7]), 'z' : np.rad2deg(fictrac_data[7])})\n",
    "\n",
    "    hf_path = f'{processed_path}/fictrac.h5'\n",
    "    with h5py.File(hf_path,'w') as hf:\n",
    "        hf.create_dataset('fictrac_time', data = fictrac_data[0])\n",
    "        hf.create_dataset('smoothed_speed', data=smoothed_speed)\n",
    "        hf.create_dataset('2d_pos', data = xy_pos)\n",
    "        hf.create_dataset('delta_rot', data = delta_rot)\n",
    "    hf.close()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed experiments: ['251014_1701', '251014_1801']\n",
      "unprocessed experiments: ['251024_1901', '251024_2001']\n",
      "working on: 251024_1901\n",
      "    made processed directory\n",
      "    running motion correction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "** ERROR: NWAD: wrote only 880803840 of 3143445504 bytes to file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    clustering pixels\n",
      "    caculating df/F signal\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 76\u001B[0m\n\u001B[1;32m     73\u001B[0m hf\u001B[38;5;241m.\u001B[39mclose()\n\u001B[1;32m     75\u001B[0m \u001B[38;5;66;03m# load in csv\u001B[39;00m\n\u001B[0;32m---> 76\u001B[0m csv_file \u001B[38;5;241m=\u001B[39m \u001B[43mglob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mglob\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m*csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m     78\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m    saving acquisition parameters\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     79\u001B[0m ttls \u001B[38;5;241m=\u001B[39m ttl\u001B[38;5;241m.\u001B[39mread_csv(csv_file)\n",
      "\u001B[0;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T23:52:48.162406Z",
     "start_time": "2025-11-05T23:52:48.156636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def write_h5(raw_path, processed_path):\n",
    "    dat_file = glob.glob(os.path.join(raw_path, '*.dat'))[0]\n",
    "    fictrac_data = pd.DataFrame(pd.read_csv(dat_file, header=None))\n",
    "\n",
    "    print('    smoothing and saving fictrac speed')\n",
    "    win_size = int(.5 * camera_framerate)\n",
    "    inst_speed = np.rad2deg(fictrac_data[18])\n",
    "    smoothed_speed = savgol_filter(inst_speed, win_size, 3)\n",
    "\n",
    "    xy_pos = pd.DataFrame({'x': fictrac_data[14], 'y': fictrac_data[15]})\n",
    "    delta_rot = pd.DataFrame({'x': np.rad2deg(fictrac_data[5]), 'y': np.rad2deg(fictrac_data[7]), 'z' : np.rad2deg(fictrac_data[7])})\n",
    "\n",
    "    hf_path = f'{processed_path}/fictrac.h5'\n",
    "    with h5py.File(hf_path,'w') as hf:\n",
    "        hf.create_dataset('fictrac_time', data = fictrac_data[0])\n",
    "        hf.create_dataset('smoothed_speed', data=smoothed_speed)\n",
    "        hf.create_dataset('2d_pos', data = xy_pos)\n",
    "        hf.create_dataset('delta_rot', data = delta_rot)\n",
    "    hf.close()"
   ],
   "id": "d7b65be1b28aa739",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T23:53:06.595992Z",
     "start_time": "2025-11-05T23:53:06.569556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "base_data_path = \"/Volumes/AhmedLab/princess/data\"\n",
    "exp = 1801\n",
    "\n",
    "# set experiment file path\n",
    "raw_path = glob.glob(os.path.join(base_data_path, 'raw', f'*{exp}'))[0]\n",
    "processed_path = glob.glob(os.path.join(base_data_path, 'processed', f'*{exp}'))[0]\n",
    "print(processed_path)"
   ],
   "id": "3325b06f879dbb30",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/AhmedLab/princess/data/processed/251014_1801\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T23:53:57.449771Z",
     "start_time": "2025-11-05T23:53:56.997901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scope_fr, camera_framerate, brain_dim = io.load_acquisition_params(processed_path)\n",
    "write_h5(raw_path, processed_path)"
   ],
   "id": "9cd6a9d19317fed6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    smoothing and saving fictrac speed\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "623738227dbcdb4f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maui",
   "language": "python",
   "name": "maui"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
