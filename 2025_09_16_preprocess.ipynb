{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d0b4f4d0882d587",
   "metadata": {},
   "source": [
    "To do:\n",
    "- [ ] fix motion correction part\n",
    "- how do I save out motion corrected brain and how does this affect later analyses\n",
    "- [ ] calculate pearson correlations, save out that info into another h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T18:10:26.746933Z",
     "start_time": "2025-09-18T18:10:25.701065Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import glob\n",
    "import h5py\n",
    "import pandas as pd\n",
    "\n",
    "from src import io, moco, roi, ttl, zdF\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63b4895ffc2bb68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T18:11:13.772797Z",
     "start_time": "2025-09-18T18:10:26.751078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ptarabishi/repos/ROI_analysis/251014_1701\n"
     ]
    }
   ],
   "source": [
    "# set these each time\n",
    "\n",
    "exp_date = '251014'\n",
    "exp_num = '1701'\n",
    "\n",
    "experiment_path = io.get_experiment(exp_date, exp_num)\n",
    "print(experiment_path)\n",
    "# set raw imaging and camera files\n",
    "# if this fails, make sure you're connected to psych server\n",
    "\n",
    "csv_path = io.get_file(experiment_path,'raw', '.csv')\n",
    "green_path = io.get_file(experiment_path,'raw', 'channel_1.nii')\n",
    "xml_path = io.get_file(experiment_path,'raw', '.xml')\n",
    "\n",
    "# set raw fictrac data\n",
    "dat_path = io.get_file(experiment_path,'raw', '.dat')\n",
    "\n",
    "func_brain = io.load(green_path)\n",
    "\n",
    "n_slices = func_brain.shape[2]  # z\n",
    "n_vols = func_brain.shape[-1]  # t\n",
    "print('x, y, z, t', func_brain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b03a6978a306b1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T18:11:13.794924Z",
     "start_time": "2025-09-18T18:11:13.791309Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'func_brain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dim \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(func_brain\u001b[38;5;241m.\u001b[39mshape, )\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mtype\u001b[39m(dim)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'func_brain' is not defined"
     ]
    }
   ],
   "source": [
    "dim = pd.DataFrame(func_brain.shape, )\n",
    "type(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55d0175ff96205a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T18:11:13.801354Z",
     "start_time": "2025-09-18T18:11:13.799564Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# moco_brain = moco.motion_correction(func_brain, func_brain)\n",
    "# need to work on this way more"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851c97af4fd918b0",
   "metadata": {},
   "source": [
    "# to extract ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe96e0ce0a5d4f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T18:11:13.820261Z",
     "start_time": "2025-09-18T18:11:13.815436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed folder already exists\n"
     ]
    }
   ],
   "source": [
    "processed_dir = fr'{experiment_path}/processed/'\n",
    "if not os.path.isdir(processed_dir):\n",
    "    os.mkdir(processed_dir)\n",
    "    print(\"Processed folder created\")\n",
    "else:\n",
    "    print(\"Processed folder already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b13ca445c5e41c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T18:13:32.575227Z",
     "start_time": "2025-09-18T18:11:13.824883Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster labels already saved in /Volumes/AhmedLab/princess/data/250829_1301/processed/TSeries-08292025-1301_channel_1_labels.h5\n",
      "calculating df/F signal\n",
      "saving acquisition frame rates\n",
      "smoothing fictrac speed\n",
      "supervoxel data saved as /Volumes/AhmedLab/princess/data/250829_1301/processed/250829_1301_supervoxels.h5\n"
     ]
    }
   ],
   "source": [
    "processed_path = glob.glob(fr'{processed_dir}*supervoxels.h5')\n",
    "labels_path = glob.glob(fr'{processed_dir}*labels.h5')\n",
    "\n",
    "# check for labels.h5 or extract ROIs from moco brain\n",
    "if labels_path:\n",
    "    print(fr'cluster labels already saved in {labels_path[0]}')\n",
    "else:\n",
    "    path = fr'{processed_dir}/{exp_date}_{exp_num}_labels.h5'\n",
    "    print('cluster labels h5 file made')\n",
    "    hf = h5py.File(path, 'w')\n",
    "\n",
    "    print('generating clusters')\n",
    "    labels = roi.extract_ROIs(func_brain, n_clusters=200)\n",
    "    hf.create_dataset('labels', data=labels)\n",
    "    hf.close()\n",
    "\n",
    "if processed_path:\n",
    "    print(f'supervoxel data already saved in {processed_path[0]}')\n",
    "else:\n",
    "    # open labels file\n",
    "    labels_hf = h5py.File(labels_path[0], 'r')\n",
    "    labels = labels_hf['labels'][...]\n",
    "\n",
    "    path = fr'{processed_dir}/{exp_date}_{exp_num}_supervoxels.h5'\n",
    "    print('calculating df/F signal')\n",
    "    df = zdF.calculate_zscoredF(func_brain, labels, n_clusters=200)\n",
    "\n",
    "    print('saving acquisition frame rates')\n",
    "    ttls = ttl.read_csv(csv_path)\n",
    "    scope_timestamps = ttl.extract_2p_relative_timestamps(ttls)\n",
    "    camera_timestamps = ttl.extract_camera_relative_timestamps(ttls)\n",
    "    scope_framerate = ttl.get_frame_rate(pd.Series(scope_timestamps))\n",
    "    camera_framerate = ttl.get_frame_rate(pd.Series(camera_timestamps))\n",
    "\n",
    "    print('smoothing fictrac speed')\n",
    "    fictrac_data = pd.DataFrame(pd.read_csv(dat_path, header=None))\n",
    "    # for window size of 500 ms\n",
    "    win_size = int(.5 * camera_framerate)\n",
    "    inst_speed = np.rad2deg(fictrac_data[18])\n",
    "    smoothed_speed = savgol_filter(inst_speed, win_size, 3)\n",
    "\n",
    "    with h5py.File(path,'w') as hf:\n",
    "        hf.create_dataset('ca_signal', data=df)\n",
    "        hf.create_dataset('scope_fr', data=scope_framerate)\n",
    "        hf.create_dataset('camera_fr', data=camera_framerate)\n",
    "        hf.create_dataset('smoothed_speed', data=smoothed_speed)\n",
    "        hf.create_dataset('fictrac_time', data = fictrac_data[0])\n",
    "        hf.create_dataset('brain_dimensions', data = dim)\n",
    "\n",
    "    hf.close()\n",
    "    print(f'supervoxel data saved as {processed_path[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1e599e26aa826d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T18:13:32.670977Z",
     "start_time": "2025-09-18T18:13:32.669513Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
